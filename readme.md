<div align="center">
  <h1>Natural Multimodal Fusion-Based Human–Robot Interaction: Application With Voice and Deictic Posture via Large Language Model</h1>
  <h2>Originally Submitted as: NMM-HRI – Natural Multi-modal HRI with Voice and Deictic Posture via Large Language Model</h2>
  <p><strong>Yuzhi Lai, Shenghai Yuan, Youssef Nassar, Mingyu Fan, Atmaraaj Gopal, Arihiro Yorita, Naoyuki Kubota, Matthias Rätsch</strong></p>
  <br>

  [![IEEE Xplore](https://img.shields.io/badge/IEEE-Paper-blue)](https://ieeexplore.ieee.org/document/10910098)
  [![DOI](https://img.shields.io/badge/DOI-10.1109%2FMRA.2025.3543957-blue)](https://doi.org/10.1109/MRA.2025.3543957)
  [![arXiv](https://img.shields.io/badge/arXiv-2501.00785-b31b1b.svg)](https://arxiv.org/abs/2501.00785)
  [![YouTube](https://img.shields.io/badge/YouTube-FF0000?logo=youtube&logoColor=white)](https://youtu.be/pv9Q4zOgBnk)
  [![GitHub](https://img.shields.io/badge/Code-Repository-black?logo=github)](https://github.com/laiyuzhi/NMM-HRI)

  <br><br>

  <strong>This work has been published in <i>IEEE Robotics and Automation Magazine (RAM)</i>, 2025.</strong>
</div>
